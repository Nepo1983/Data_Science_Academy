{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Matemática Para Data Science</font>\n",
    "\n",
    "## <font color='blue'>Estudo de Caso 3</font>\n",
    "### <font color='blue'>Operações com Matrizes em Redes Neurais Artificiais</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](CAP06/imagens/EC3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.18\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "# Você pode usar a versão indicada nos vídeos ou a versão abaixo!\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "# !pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import typing as List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "numpy: 1.26.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos uma classe Python que descreve uma rede neural artificial apenas com operações matemáticas. Não se deixe impressionar pelo código, é bem mais simples do que parece!!\n",
    "\n",
    "Vamos detalhar as operações matemáticas dessa função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe\n",
    "class NeuralNetwork(object):\n",
    "\n",
    "    # Método construtor\n",
    "    def __init__(self, sizes: list[int]) -> None:    \n",
    "        \n",
    "        \"\"\"A lista `sizes` contém o número de neurônios nas\n",
    "         respectivas camadas da rede. Por exemplo, se a lista\n",
    "         for [2, 3, 1] então será uma rede de três camadas, com o\n",
    "         primeira camada contendo 2 neurônios, a segunda camada 3 neurônios,\n",
    "         e a terceira camada 1 neurônio. Bias e pesos para a\n",
    "         rede são inicializados aleatoriamente, usando uma distribuição Gaussiana com média 0 e variância 1. \n",
    "         Note que a primeira camada é assumida como uma camada de entrada, e por convenção nós\n",
    "         não definimos nenhum bias para esses neurônios, pois os bias são usados\n",
    "         na computação das saídas das camadas posteriores.\"\"\"\n",
    "\n",
    "        # Número de camadas\n",
    "        self.num_layers = len(sizes)\n",
    "        \n",
    "        # Define o atributos sizes\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        # Cria um vetor de valores randômicos para inicializar o bias. \n",
    "        # A função randn cria valores randômicos que seguem uma distribuição normal.\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        \n",
    "        # Cria a matriz de valores randômicos para inicializar os pesos. \n",
    "        # A função randn cria valores randômicos que seguem uma distribuição normal.\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "        \n",
    "    # Método feed forward\n",
    "    # Este método faz a passada para frente até a previsão com a função sigmoid.\n",
    "    def feedforward(self, a):\n",
    "        \n",
    "        # Utiliza os valores de peso e bias aprendidos no treinamento para fazer previsões com x\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "                        \n",
    "            # Produto escalar e soma\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "        \n",
    "    # Método SGD\n",
    "    # Usado para treinar o modelo com algoritmo stochastic gradient descent\n",
    "    def treina_modelo(self, training_data, epochs, mini_batch_size, taxa_aprendizado, test_data = None):\n",
    "\n",
    "        # Recebe a matriz com os dados de entrada e converte em uma lista\n",
    "        training_data = list(training_data)\n",
    "        \n",
    "        # Comprimento da matriz\n",
    "        n = len(training_data)\n",
    "\n",
    "        # Verifica se tem dados de teste\n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "\n",
    "        # Loop pelo número de épocas (passadas de treinamento)\n",
    "        for j in range(epochs):\n",
    "            \n",
    "            # Embaralha os dados de treino\n",
    "            random.shuffle(training_data)\n",
    "            \n",
    "            # Extrai um mini-batch (lote) dos dados\n",
    "            mini_batches = [training_data[k: k + mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            \n",
    "            # Atualiza os pesos com o método atualiza_pesos\n",
    "            for mini_batch in mini_batches:\n",
    "                self.atualiza_pesos(mini_batch, taxa_aprendizado)\n",
    "            \n",
    "            # Imprime o andamento\n",
    "            if test_data:\n",
    "                print(f\"Epoch {j} : {self.evaluate(test_data)} / {n_test}\")\n",
    "            else:\n",
    "                print(f\"Epoch {j} finalizada\")\n",
    "                \n",
    "    # Método de atualização dos pesos\n",
    "    # Atualiza pesos e bias conforme aprendizado do algoritmo\n",
    "    def atualiza_pesos(self, mini_batch, taxa_aprendizado):\n",
    "        \n",
    "        # Cria as matrizes para os valores parciais de bias e pesos\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # Para cada par de dados no lote, executa o aprendizado com o algoritmo backpropagation\n",
    "        for x, y in mini_batch:\n",
    "            \n",
    "            # Calcula as derivadas parciais de pesos e bias\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            \n",
    "            # Atualiza as matrizes parciais de pesos e bias com os novos valores\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        \n",
    "        # Atualiza as matrizes principais de pesos e bias\n",
    "        self.weights = [w - (taxa_aprendizado / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - (taxa_aprendizado / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "    \n",
    "    # Método do algoritmo backpropagation\n",
    "    # Retorna tuplas representando o gradiente para a função de custo.\n",
    "    def backprop(self, x, y):\n",
    "        \n",
    "        # Matrizes parciais\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # Feedforward\n",
    "        activation = x\n",
    "\n",
    "        # Lista para armazenar todas as ativações, camada por camada\n",
    "        activations = [x]\n",
    "\n",
    "        # Lista para armazenar todos os vetores z, camada por camada\n",
    "        zs = []\n",
    "\n",
    "        # Loop pelas matrizes de pesos e bias\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            \n",
    "            # Produto escalar\n",
    "            z = np.dot(w, activation) + b\n",
    "                        \n",
    "            # Append\n",
    "            zs.append(z)\n",
    "            \n",
    "            # Ativação\n",
    "            activation = sigmoid(z)\n",
    "            \n",
    "            # Append\n",
    "            activations.append(activation)\n",
    "        \n",
    "        # Backward pass\n",
    "        delta = self.derivada_custo(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        # Aqui, l = 1 significa a última camada de neurônios, l = 2 é a segunda e assim por diante.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    \n",
    "    # Método de avaliação\n",
    "    def evaluate(self, test_data):\n",
    "        \n",
    "        # Resultados de avaliação do modelo\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        \n",
    "        return sum(int(x = y) for (x, y) in test_results)\n",
    "\n",
    "    \n",
    "    # Derivada do custo\n",
    "    def derivada_custo(self, output_activations, y):\n",
    "        \"\"\"Retorna o vetor das derivadas parciais.\"\"\"\n",
    "        return (output_activations - y)\n",
    "    \n",
    "    # Função de Ativação Sigmóide\n",
    "    def sigmoid(z):\n",
    "        return 1.0/(1.0 + np.exp(-z))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [2, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_v1 = NeuralNetwork(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
